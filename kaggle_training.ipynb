{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb2ebac",
   "metadata": {},
   "source": [
    "# Pacman RL Training on Kaggle\n",
    "## Enhanced Reward Shaping - All Algorithms\n",
    "\n",
    "This notebook trains 4 Deep RL algorithms (DQN, PPO, A2C, Rainbow) on Pacman with custom reward shaping.\n",
    "\n",
    "**Training Configuration:**\n",
    "- **Environment:** ALE/Pacman-v5 with OCAtari\n",
    "- **Algorithms:** DQN, PPO, A2C, Rainbow (QR-DQN)\n",
    "- **Total Timesteps:** 2,000,000 per algorithm\n",
    "- **Reward Shaping:** 10-component enhanced wrapper\n",
    "- **Device:** GPU (CUDA) for faster training\n",
    "\n",
    "**Estimated Time:** 10-14 hours for all 4 algorithms\n",
    "\n",
    "**Repository:** https://github.com/lequangdung2005/IntroAI-2025.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5990102",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Install System Dependencies\n",
    "\n",
    "First, we need to install git and other system dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becf650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9e4af7",
   "metadata": {},
   "source": [
    "## üîΩ Step 2: Clone GitHub Repository\n",
    "\n",
    "Clone the repository containing the Pacman RL training code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7507635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/lequangdung2005/IntroAI-2025.1.git\n",
    "\n",
    "print(\"‚úÖ Repository cloned successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229ceb97",
   "metadata": {},
   "source": [
    "## üìÇ Step 3: Navigate to Repository Directory\n",
    "\n",
    "Change to the Pacman project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7c53ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Change to the Pacman directory\n",
    "os.chdir('/kaggle/working/IntroAI-2025.1/Pacman')\n",
    "\n",
    "# Verify current directory\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "print(f\"Contents:\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0a25dd",
   "metadata": {},
   "source": [
    "## ‚úÖ Step 4: Verify Repository Contents\n",
    "\n",
    "Check that all necessary files are present in the enhanced_algorithm directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af71caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check enhanced_algorithm directory\n",
    "print(\"Enhanced algorithm directory contents:\")\n",
    "!ls -la enhanced_algorithm/\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training scripts available:\")\n",
    "!ls -1 enhanced_algorithm/train_*.py\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Batch training script:\")\n",
    "!ls -la enhanced_algorithm/train_all_enhanced.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fded8faf",
   "metadata": {},
   "source": [
    "## üì• Step 5: Install Python Dependencies\n",
    "\n",
    "Install all required Python packages for RL training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda396f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q gymnasium ale-py stable-baselines3 sb3-contrib ocatari opencv-python\n",
    "\n",
    "# Verify installations\n",
    "print(\"\\n‚úÖ Checking installations...\")\n",
    "import gymnasium\n",
    "import ale_py\n",
    "import stable_baselines3\n",
    "import sb3_contrib\n",
    "import cv2\n",
    "\n",
    "print(f\"‚úì Gymnasium: {gymnasium.__version__}\")\n",
    "print(f\"‚úì ALE-py: {ale_py.__version__}\")\n",
    "print(f\"‚úì Stable-Baselines3: {stable_baselines3.__version__}\")\n",
    "print(f\"‚úì SB3-Contrib: {sb3_contrib.__version__}\")\n",
    "print(f\"‚úì OpenCV: {cv2.__version__}\")\n",
    "print(\"\\n‚úÖ All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c47b20",
   "metadata": {},
   "source": [
    "## üéÆ Step 6: Check GPU Availability\n",
    "\n",
    "Verify that GPU is available for faster training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92afd0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"GPU device:\", torch.cuda.get_device_name(0))\n",
    "    print(\"GPU memory:\", torch.cuda.get_device_properties(0).total_memory / 1e9, \"GB\")\n",
    "    print(\"\\n‚úÖ GPU is available! Training will be fast.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  GPU not available. Training will use CPU (slower).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beefde7b",
   "metadata": {},
   "source": [
    "## üöÄ Step 7: Run Training Script\n",
    "\n",
    "Execute the batch training script to train all 4 algorithms sequentially.\n",
    "\n",
    "**This will train:**\n",
    "1. **DQN** - Deep Q-Network (~2-3 hours)\n",
    "2. **PPO** - Proximal Policy Optimization (~3-4 hours)\n",
    "3. **A2C** - Advantage Actor-Critic (~2-3 hours)\n",
    "4. **Rainbow** - QR-DQN (~3-4 hours)\n",
    "\n",
    "**Total estimated time: 10-14 hours**\n",
    "\n",
    "‚ö†Ô∏è **Note:** Make sure GPU is enabled in Kaggle settings for faster training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dabbab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the script executable\n",
    "!chmod +x enhanced_algorithm/train_all_enhanced.sh\n",
    "\n",
    "# Run the batch training script\n",
    "print(\"üöÄ Starting training for all 4 algorithms...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "!bash enhanced_algorithm/train_all_enhanced.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af203ef7",
   "metadata": {},
   "source": [
    "## üìä Step 8: Display Training Results\n",
    "\n",
    "Check the trained models and their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a492a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all trained models\n",
    "print(\"‚úÖ Training Complete! Checking trained models...\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check DQN models\n",
    "print(\"\\nüìÅ DQN Models:\")\n",
    "!ls -lh models/enhanced_dqn/*.zip 2>/dev/null || echo \"No DQN models found\"\n",
    "\n",
    "# Check PPO models\n",
    "print(\"\\nüìÅ PPO Models:\")\n",
    "!ls -lh models/enhanced_ppo/*.zip 2>/dev/null || echo \"No PPO models found\"\n",
    "\n",
    "# Check A2C models\n",
    "print(\"\\nüìÅ A2C Models:\")\n",
    "!ls -lh models/enhanced_a2c/*.zip 2>/dev/null || echo \"No A2C models found\"\n",
    "\n",
    "# Check Rainbow models\n",
    "print(\"\\nüìÅ Rainbow Models:\")\n",
    "!ls -lh models/enhanced_rainbow/*.zip 2>/dev/null || echo \"No Rainbow models found\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"All models saved in the 'models/' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fec9036",
   "metadata": {},
   "source": [
    "## üìà Step 9: View Training Logs\n",
    "\n",
    "Check the training logs to see performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e5d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check log directories\n",
    "print(\"Training logs directory structure:\")\n",
    "!ls -la logs/\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Available log directories:\")\n",
    "!ls -1 logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0c5b46",
   "metadata": {},
   "source": [
    "## üíæ Step 10: Save Models as Output\n",
    "\n",
    "Copy trained models to Kaggle output for download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87144aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"/kaggle/working/trained_models\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Copy all model directories\n",
    "algorithms = ['enhanced_dqn', 'enhanced_ppo', 'enhanced_a2c', 'enhanced_rainbow']\n",
    "\n",
    "for algo in algorithms:\n",
    "    src = f\"models/{algo}\"\n",
    "    dst = f\"{output_dir}/{algo}\"\n",
    "    if os.path.exists(src):\n",
    "        shutil.copytree(src, dst, dirs_exist_ok=True)\n",
    "        print(f\"‚úÖ Copied {algo} models\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  {algo} models not found\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"All models saved to:\", output_dir)\n",
    "print(\"You can download them from the Kaggle output section.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c28ff1",
   "metadata": {},
   "source": [
    "## üéâ Training Summary\n",
    "\n",
    "### What Was Trained:\n",
    "\n",
    "| Algorithm | Type | Timesteps | Expected Score |\n",
    "|-----------|------|-----------|----------------|\n",
    "| **DQN** | Value-based | 2,000,000 | 1200-1800 |\n",
    "| **PPO** | Policy-based | 2,000,000 | 1400-2200 |\n",
    "| **A2C** | Policy-based | 2,000,000 | 1100-1600 |\n",
    "| **Rainbow** | Value-based | 2,000,000 | 1500-2500 |\n",
    "\n",
    "### Enhanced Reward Components:\n",
    "1. Score Bonus (+0.1√ó)\n",
    "2. Power Pellet Seeking (+5)\n",
    "3. Ghost Hunting (+50)\n",
    "4. Ghost Avoidance (+2)\n",
    "5. Dot Collection (+1)\n",
    "6. Movement Bonus (+0.5)\n",
    "7. Corner Penalty (-1)\n",
    "8. Survival Bonus (+0.1)\n",
    "9. Death Penalty (-100)\n",
    "10. Level Completion (+200)\n",
    "\n",
    "### Files Generated:\n",
    "- **Final models:** `pacman_{algorithm}_enhanced_final.zip`\n",
    "- **Checkpoints:** Every 50,000 steps\n",
    "- **Best models:** `best_model.zip` (best evaluation score)\n",
    "- **Logs:** TensorBoard logs in `logs/enhanced_{algorithm}/`\n",
    "\n",
    "### Next Steps:\n",
    "1. Download trained models from Kaggle output\n",
    "2. Use `play.py` to evaluate models locally\n",
    "3. Compare with baseline models\n",
    "4. Visualize training progress with TensorBoard\n",
    "\n",
    "---\n",
    "\n",
    "**‚úÖ All 4 algorithms trained successfully with enhanced reward shaping!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
